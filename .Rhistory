def predict_and_rank(neighbors: list[int] -> list[list[float], listint]):
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])
import time
import math
import json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.base import clone
import xgboost as xgb
from xgboost.callback import TrainingCallback
import plotly.graph_objects as go
import pickle
N = 12 # Number of patients
T = 18 # Number of intervals
d = 5 # Length of each interval
s = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution
q = 0.20 # Probability of a scheduled patient not showing up
w = 0.8 # Weight for the waiting time in objective function
num_schedules = 20000 # Number of schedules to sample
# Load the data from the pickle file
with open('neighbors_and_objectives.pkl', 'rb') as f:
data = pickle.load(f)
# Extract the variables from the loaded data
neighbors_list = data['neighbors_list']
objectives_list = data['objectives']
rankings_list = data['rankings']
print("Data loaded successfully.\n")
for neigbors in neighbors_list[:2]: print(neigbors, "\n")
for objectives in objectives_list[:2]: print(objectives, "\n")
for rankings in rankings_list[:2]: print(rankings, "\n")
X = np.array([X[0] for X in neighbors_list])
y = np.array([y[0] for y in objectives_list])
# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#=========================================================================
# XGBoost regression:
# Parameters:
# n_estimators  "Number of gradient boosted trees. Equivalent to number
#                of boosting rounds."
# learning_rate "Boosting learning rate (also known as “eta”)"
# max_depth     "Maximum depth of a tree. Increasing this value will make
#                the model more complex and more likely to overfit."
#=========================================================================
regressor=xgb.XGBRegressor(eval_metric='rmsle')
#=========================================================================
# exhaustively search for the optimal hyperparameters
#=========================================================================
from sklearn.model_selection import GridSearchCV
# set up our search grid
param_grid = {"max_depth":    [4, 5, 7],
"n_estimators": [500, 700, 900],
"learning_rate": [0.05, 0.1, 0.15]}
# try out every combination of the above values
start = time.time()
search = GridSearchCV(regressor, param_grid, cv=5, verbose=3).fit(X_train, y_train)
end = time.time()
hyper_search_time = end - start
print(f'Hyperparameter optimization time: {hyper_search_time}')
print("The best hyperparameters are ",search.best_params_)
regressor=xgb.XGBRegressor(learning_rate = search.best_params_["learning_rate"],
n_estimators  = search.best_params_["n_estimators"],
max_depth     = search.best_params_["max_depth"],
eval_metric='rmsle')
regressor.fit(X_train, y_train)
predictions = regressor.predict(X_test)
from sklearn.metrics import mean_squared_log_error
RMSLE = np.sqrt( mean_squared_log_error(y_test, predictions) )
print("The score is %.5f" % RMSLE )
import plotly.graph_objects as go
# Create the scatter plot
fig = go.Figure()
fig.add_trace(go.Scatter(
x=y_test,
y=predictions,
mode='markers',
marker=dict(color='blue'),
name='Predictions vs. true values'
))
fig.add_trace(go.Scatter(
x=[0, max(max(y_test), max(predictions))],
y=[0, max(max(y_test), max(predictions))],
mode='lines',
line=dict(color='tomato', dash='dash'),
name='Base line',
))
# Add axis labels and a title
fig.update_layout(
title='Predictions vs. true values',
xaxis_title='True values',
yaxis_title='Predictions',
showlegend=True
)
# Show the plot
fig.show()
num_test_schedules = 1000
test_schedules = random_combination_with_replacement(T, N, num_test_schedules)
test_neighbors = create_neighbors_list(test_schedules)
print(f"Sampled: {len(test_schedules)} schedules\n")
test_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]
# Start time measeurement for the evaluation
start = time.time()
test_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj < test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]
end = time.time()
evaluation_time = end - start
# Combine the objectives for each pair for later processing
test_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]
print(f"\nEvaluation time: {evaluation_time} seconds\n")
for i in range(6):
print(f"Neighbors: {test_neighbors[i]},\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\n")
def predict_and_rank(neighbors: list[int] -> list[list[float], listint]):
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])
def def predict_and_rank(neighbors: list[int]) -> tuple[list[list[float]], int]:
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])
def predict_and_rank(neighbors: list[int]) -> tuple[list[list[float]], int]:
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])
def predict_and_rank(neighbors: list[list[int]]) -> tuple[list[list[float]], int]:
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])
def predict_and_rank(neighbors: list[list[int]]) -> tuple[list[list[float]], int]:
predictions = [regressor.predict(neighbor) for neighbor in neighbors]
ranking = np.argmin(predictions, axis=1)
return predictions, rankings
predict_and_rank([[6, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [6, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]])
import time
import math
import json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.base import clone
import xgboost as xgb
from xgboost.callback import TrainingCallback
import plotly.graph_objects as go
import pickle
import functions
num_test_schedules = 1000
test_schedules = random_combination_with_replacement(T, N, num_test_schedules)
test_neighbors = create_neighbors_list(test_schedules)
print(f"Sampled: {len(test_schedules)} schedules\n")
test_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]
# Start time measeurement for the evaluation
start = time.time()
test_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj < test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]
end = time.time()
evaluation_time = end - start
# Combine the objectives for each pair for later processing
test_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]
print(f"\nEvaluation time: {evaluation_time} seconds\n")
for i in range(6):
print(f"Neighbors: {test_neighbors[i]},\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\n")
reticulate::repl_python()
