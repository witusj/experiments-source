# Function to process a single N
def process_schedule(n, T, s, d, q, w, v_star):
print(f'Running local search for schedule with N={n}')
x = build_welch_bailey_schedule(n, T)
convolutions = compute_convolutions(s, n, q)
schedules, objectives = local_search_w_intermediates(x, d, q, convolutions, w, v_star, T)
return {
'n': n,
'x_initial': x,
'schedules': schedules,
'objectives': objectives,
'x_star': schedules[-1],
'obj_val': objectives[-1],
}
# Parameters
N = range(21, 22)
T = 20
s = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]
d = 2
q = 0.1
w = 0.9
v_star = get_v_star(T)
# Lists to store results
results = []
start = time.time()
# Use ThreadPoolExecutor for parallelism
with ThreadPoolExecutor() as executor:
# Map the function to the range of N
futures = [executor.submit(process_schedule, n, T, s, d, q, w, v_star) for n in N]
for future in futures:
results.append(future.result())
end = time.time()
# Extract results
x_initials = [result['x_initial'] for result in results]
schedules_list = [result['schedules'] for result in results]
objectives_list = [result['objectives'] for result in results]
x_stars = [result['x_star'] for result in results]
obj_vals = [result['obj_val'] for result in results]
print("Optimized Schedules:", x_stars)
print("Objective Values:", obj_vals)
print(f"Search time: {end - start:.2f} seconds")
import itertools
import networkx as nx
import plotly.graph_objects as go
import numpy as np
from typing import List, Tuple
import plotly.subplots as sp
from plotly.subplots import make_subplots
from concurrent.futures import ThreadPoolExecutor
import time
from functions import create_random_schedules, calculate_objective, compute_convolutions, local_search, get_v_star, powerset, get_neighborhood, build_welch_bailey_schedule, service_time_with_no_shows, create_schedule_network, create_schedule_network_var_edges, create_schedule_network_from_lists, local_search_w_intermediates
# Function to process a single N
def process_schedule(n, T, s, d, q, w, v_star):
print(f'Running local search for schedule with N={n}')
x = build_welch_bailey_schedule(n, T)
convolutions = compute_convolutions(s, n, q)
schedules, objectives = local_search_w_intermediates(x, d, q, convolutions, w, v_star, T)
return {
'n': n,
'x_initial': x,
'schedules': schedules,
'objectives': objectives,
'x_star': schedules[-1],
'obj_val': objectives[-1],
}
# Parameters
N = range(21, 22)
T = 20
s = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]
d = 2
q = 0.1
w = 0.9
v_star = get_v_star(T)
# Lists to store results
results = []
start = time.time()
# Use ThreadPoolExecutor for parallelism
with ThreadPoolExecutor() as executor:
# Map the function to the range of N
futures = [executor.submit(process_schedule, n, T, s, d, q, w, v_star) for n in N]
for future in futures:
results.append(future.result())
end = time.time()
# Extract results
x_initials = [result['x_initial'] for result in results]
schedules_list = [result['schedules'] for result in results]
objectives_list = [result['objectives'] for result in results]
x_stars = [result['x_star'] for result in results]
obj_vals = [result['obj_val'] for result in results]
print("Optimized Schedules:", x_stars)
print("Objective Values:", obj_vals)
print(f"Search time: {end - start:.2f} seconds")
reticulate::repl_python()
