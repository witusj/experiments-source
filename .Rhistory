N = 12
T = 18
d = 5
s = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1]
q = 0.20
from functions import random_combination_with_replacement
num_schedules = 20000
schedules = random_combination_with_replacement(T, N, num_schedules)
for schedule in schedules[:5]:
print(f"Schedule: {schedule}")
from functions import create_neighbors_list
neighbors = create_neighbors_list(schedules)
for neighbor in neighbors[:5]:
print(f"Neighbor: {neighbor[1]}")
from functions import calculate_objective
objectives = [[calculate_objective(neighbor[0], s, d, q), calculate_objective(neighbor[1], s, d, q)] for neighbor in neighbors]
rankings = [0 if obj[0] < obj[1] else 1 for obj in objectives]
for i in range(5):
print(f"Objectives: {objectives[i]}, Ranking: {rankings[i]}")
# Prepare the dataset
X = []
for neighbor in neighbors:
X.append(neighbor[0] + neighbor[1])
X = np.array(X)
y = np.array(rankings)
# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
import numpy as np
# Prepare the dataset
X = []
for neighbor in neighbors:
X.append(neighbor[0] + neighbor[1])
X = np.array(X)
y = np.array(rankings)
# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
import numpy as np
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
# Prepare the dataset
X = []
for neighbor in neighbors:
X.append(neighbor[0] + neighbor[1])
X = np.array(X)
y = np.array(rankings)
# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
def fit_and_score(estimator, X_train, X_test, y_train, y_test):
"""Fit the estimator on the train set and score it on both sets"""
estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)])
train_score = estimator.score(X_train, y_train)
test_score = estimator.score(X_test, y_test)
return estimator, train_score, test_score
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100,
early_stopping_rounds=10
)
results = []
for train_idx, test_idx in cv.split(X, y):
X_train, X_test = X[train_idx], X[test_idx]
y_train, y_test = y[train_idx], y[test_idx]
est, train_score, test_score = fit_and_score(
clone(clf), X_train, X_test, y_train, y_test
)
results.append((est, train_score, test_score))
# Print results
for i, (est, train_score, test_score) in enumerate(results):
print(f"Fold {i+1} - Train Score: {train_score:.4f}, Test Score: {test_score:.4f}")
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.base import clone
import xgboost as xgb
def fit_and_score(estimator, X_train, X_test, y_train, y_test):
"""Fit the estimator on the train set and score it on both sets"""
estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)])
train_score = estimator.score(X_train, y_train)
test_score = estimator.score(X_test, y_test)
return estimator, train_score, test_score
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100,
early_stopping_rounds=10
)
results = []
for train_idx, test_idx in cv.split(X, y):
X_train, X_test = X[train_idx], X[test_idx]
y_train, y_test = y[train_idx], y[test_idx]
est, train_score, test_score = fit_and_score(
clone(clf), X_train, X_test, y_train, y_test
)
results.append((est, train_score, test_score))
# Print results
for i, (est, train_score, test_score) in enumerate(results):
print(f"Fold {i+1} - Train Score: {train_score:.4f}, Test Score: {test_score:.4f}")
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100
)
clf.fit(X, y)
num_schedules = 6
test_schedules = random_combination_with_replacement(T, N, num_schedules)
test_neighbors = create_neighbors_list(test_schedules)
test_objectives = [[calculate_objective(test_neighbor[0], s, d, q), calculate_objective(test_neighbor[1], s, d, q)] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj[0] < test_obj[1] else 1 for test_obj in test_objectives]
for i in range(5):
print(f"Neighbors: {test_neighbors}, Objectives: {objectives[i]}, Ranking: {rankings[i]}")
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100
)
clf.fit(X, y)
num_schedules = 6
test_schedules = random_combination_with_replacement(T, N, num_schedules)
test_neighbors = create_neighbors_list(test_schedules)
test_objectives = [[calculate_objective(test_neighbor[0], s, d, q), calculate_objective(test_neighbor[1], s, d, q)] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj[0] < test_obj[1] else 1 for test_obj in test_objectives]
for i in range(5):
print(f"Neighbors: {test_neighbors}, Objectives: {objectives[i]}, Ranking: {rankings[i]}\n")
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100
)
clf.fit(X, y)
num_schedules = 6
test_schedules = random_combination_with_replacement(T, N, num_schedules)
test_neighbors = create_neighbors_list(test_schedules)
test_objectives = [[calculate_objective(test_neighbor[0], s, d, q), calculate_objective(test_neighbor[1], s, d, q)] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj[0] < test_obj[1] else 1 for test_obj in test_objectives]
for i in range(5):
print(f"Neighbors: {test_neighbors[i]}, Objectives: {objectives[i]}, Ranking: {rankings[i]}\n")
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100
)
clf.fit(X, y)
num_schedules = 6
test_schedules = random_combination_with_replacement(T, N, num_schedules)
test_neighbors = create_neighbors_list(test_schedules)
test_objectives = [[calculate_objective(test_neighbor[0], s, d, q), calculate_objective(test_neighbor[1], s, d, q)] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj[0] < test_obj[1] else 1 for test_obj in test_objectives]
for i in range(5):
print(f"Neighbors: {test_neighbors[i]},\nObjectives: {objectives[i]}, Ranking: {rankings[i]}\n")
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
tree_method="hist",
max_depth=6,
min_child_weight=1,
gamma=0.1,
subsample=0.8,
colsample_bytree=0.8,
learning_rate=0.1,
n_estimators=100
)
clf.fit(X, y)
num_schedules = 6
test_schedules = random_combination_with_replacement(T, N, num_schedules)
test_neighbors = create_neighbors_list(test_schedules)
test_objectives = [[calculate_objective(test_neighbor[0], s, d, q), calculate_objective(test_neighbor[1], s, d, q)] for test_neighbor in test_neighbors]
test_rankings = [0 if test_obj[0] < test_obj[1] else 1 for test_obj in test_objectives]
for i in range(5):
print(f"Neighbors: {test_neighbors[i]},\nObjectives: {objectives[i]}, Ranking: {rankings[i]}\n")
input_X = test_neighbors
X_new = []
for pair in input_X:
X_new.append(pair[0] + pair[1])
# Predict the target for new data
y_pred = clf.predict(X_new)
# If you want to get the probability estimates
y_pred_proba = clf.predict_proba(X_new)
print(f"y_pred = {y_pred}, \ny_pred_proba = \n{y_pred_proba}")
