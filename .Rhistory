import time
import math
import json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.base import clone
import xgboost as xgb
from xgboost.callback import TrainingCallback
import plotly.graph_objects as go
import pickle
import random
from scipy.optimize import minimize
from itertools import combinations
from functions import compute_convolutions
N = 22 # Number of patients
T = 20 # Number of intervals
d = 5 # Length of each interval
max_s = 20 # Maximum service time
q = 0.20 # Probability of a scheduled patient not showing up
w = 0.1 # Weight for the waiting time in objective function
l = 10
num_schedules = 20 # Number of schedules to sample
# Create service time distribution
def generate_weighted_list(max_s, l, i):
# Initialize an array of T+1 values, starting with zero
values = np.zeros(T + 1)
# Objective function: Sum of squared differences between current weighted average and the desired l
def objective(x):
weighted_avg = np.dot(np.arange(1, T + 1), x) / np.sum(x)
return (weighted_avg - l) ** 2
# Constraint: The sum of the values from index 1 to T must be 1
constraints = ({
'type': 'eq',
'fun': lambda x: np.sum(x) - 1
})
# Bounds: Each value should be between 0 and 1
bounds = [(0, 1)] * T
# Initial guess: Random distribution that sums to 1
initial_guess = np.random.dirichlet(np.ones(T))
# Optimization: Minimize the objective function subject to the sum and bounds constraints
result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)
# Set the values in the array (index 0 remains 0)
values[1:] = result.x
# Now we need to reorder the values as per the new requirement
first_part = np.sort(values[1:i+1])  # Sort the first 'i' values in ascending order
second_part = np.sort(values[i+1:])[::-1]  # Sort the remaining 'T-i' values in descending order
# Combine the sorted parts back together
values[1:i+1] = first_part
values[i+1:] = second_part
return values
i = 5  # First 5 highest values in ascending order, rest in descending order
s = generate_weighted_list(max_s, l, i)
print(s)
print("Sum:", np.sum(s[1:]))  # This should be 1
print("Weighted service time:", np.dot(np.arange(1, T + 1), s[1:]))  # This should be close to l
convolutions = compute_convolutions(s, N, q)
file_path_parameters = f"datasets/parameters_{N}_{T}_{l}.pkl"
with open(file_path_parameters, 'wb') as f:
pickle.dump({
'N': N,
'T': T,
'd': d,
'max_s': max_s,
'q': q,
'w': w,
'l': l,
'num_schedules': num_schedules,
'convolutions': convolutions
}, f)
print(f"Data saved successfully to '{file_path_parameters}'")
from functions import build_quasi_optimal_schedule
x_hat = build_quasi_optimal_schedule(N, T)
print(f"The initial schedule is: {x_hat}")
from functions import create_neighbors_list
R = [create_neighbors_list(x_hat) for i in range(num_schedules)]
for r in R[:5]: print(f"{r[0]}\n{r[1]}\n{[a - b for a, b in zip(r[0], r[1])]}\n\n")
from functions import compute_convolutions
N = 22 # Number of patients
T = 20 # Number of intervals
d = 5 # Length of each interval
max_s = 20 # Maximum service time
q = 0.20 # Probability of a scheduled patient not showing up
w = 0.1 # Weight for the waiting time in objective function
l = 10
num_schedules = 2000 # Number of schedules to sample
# Create service time distribution
def generate_weighted_list(max_s, l, i):
# Initialize an array of T+1 values, starting with zero
values = np.zeros(T + 1)
# Objective function: Sum of squared differences between current weighted average and the desired l
def objective(x):
weighted_avg = np.dot(np.arange(1, T + 1), x) / np.sum(x)
return (weighted_avg - l) ** 2
# Constraint: The sum of the values from index 1 to T must be 1
constraints = ({
'type': 'eq',
'fun': lambda x: np.sum(x) - 1
})
# Bounds: Each value should be between 0 and 1
bounds = [(0, 1)] * T
# Initial guess: Random distribution that sums to 1
initial_guess = np.random.dirichlet(np.ones(T))
# Optimization: Minimize the objective function subject to the sum and bounds constraints
result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)
# Set the values in the array (index 0 remains 0)
values[1:] = result.x
# Now we need to reorder the values as per the new requirement
first_part = np.sort(values[1:i+1])  # Sort the first 'i' values in ascending order
second_part = np.sort(values[i+1:])[::-1]  # Sort the remaining 'T-i' values in descending order
# Combine the sorted parts back together
values[1:i+1] = first_part
values[i+1:] = second_part
return values
i = 5  # First 5 highest values in ascending order, rest in descending order
s = generate_weighted_list(max_s, l, i)
print(s)
print("Sum:", np.sum(s[1:]))  # This should be 1
print("Weighted service time:", np.dot(np.arange(1, T + 1), s[1:]))  # This should be close to l
convolutions = compute_convolutions(s, N, q)
file_path_parameters = f"datasets/parameters_{N}_{T}_{l}.pkl"
with open(file_path_parameters, 'wb') as f:
pickle.dump({
'N': N,
'T': T,
'd': d,
'max_s': max_s,
'q': q,
'w': w,
'l': l,
'num_schedules': num_schedules,
'convolutions': convolutions
}, f)
print(f"Data saved successfully to '{file_path_parameters}'")
from functions import create_neighbors_list
R = [create_neighbors_list(x_hat) for i in range(num_schedules)]
for r in R[:5]: print(f"{r[0]}\n{r[1]}\n{[a - b for a, b in zip(r[0], r[1])]}\n\n")
from functions import create_neighbors_list
start = time.time()
v_star = get_v_star(T)
R = [create_neighbors_list(x_hat, v_star) for i in range(num_schedules)]
end = time.time()
for r in R[:5]: print(f"{r[0]}\n{r[1]}\n{[a - b for a, b in zip(r[0], r[1])]}\n\n")
training_set_feat_time = end - start
print(f"\nProcessing time: {training_set_feat_time} seconds\n")
from functions import create_neighbors_list, get_v_star
start = time.time()
v_star = get_v_star(T)
R = [create_neighbors_list(x_hat, v_star) for i in range(num_schedules)]
end = time.time()
for r in R[:5]: print(f"{r[0]}\n{r[1]}\n{[a - b for a, b in zip(r[0], r[1])]}\n\n")
training_set_feat_time = end - start
print(f"\nProcessing time: {training_set_feat_time} seconds\n")
reticulate::repl_python()
reticulate::repl_python()
load("~/Documents/Projects/vu/appointment-scheduling/experiments-source/.RData")
