---
title: "Phase-type distributions"
jupyter: python3
---

# **A Comprehensive Guide to Phase-Type Distributions: From Theory to Interactive Visualization in Python**

## **Introduction: Beyond the Exponential World – Modeling Time with Memory**

In the vast landscape of probability theory, distributions are the tools we use to model uncertainty. For phenomena related to waiting times, lifetimes, or durations, the exponential distribution is often the first tool reached for. Its mathematical elegance, stemming from a unique "memoryless" property, makes it exceptionally tractable.¹ This property dictates that the future lifetime of an object is independent of its current age; a 10-year-old machine has the same future life expectancy as a brand-new one. While convenient for analysis, this assumption is a profound oversimplification for most real-world systems. Processes like machine failure, patient recovery, or customer service times are rarely memoryless; their future evolution is intrinsically linked to the stages or phases they have already passed through.³

This is where the phase-type (PH) distribution emerges as a remarkably powerful and flexible framework. The core idea is both simple and profound: instead of modeling a complex lifetime with a single, complex distribution, we model it as the time taken for a system to move through a series of simple, intermediate states—or "phases"—before reaching a final, terminal state.³ Each phase represents a distinct stage of the process (e.g., 'operational', 'undergoing minor repair', 'undergoing major overhaul'), and the time spent in any single phase is exponentially distributed. By combining these simple exponential building blocks within a structured sequence, we can construct distributions of almost arbitrary shape and complexity.⁵

The power of this approach rests on two fundamental pillars that make PH distributions a cornerstone of modern stochastic modeling:

1. **Denseness:** The class of phase-type distributions is dense in the set of all probability distributions on the positive real line.⁵ This is a powerful theoretical result which means that any positive random variable, no matter how complex its underlying process, can be approximated arbitrarily well by a phase-type distribution. This makes PH distributions a near-universal tool for modeling positive-valued random phenomena.  
2. **Tractability:** Despite their generality, PH distributions are defined by a set of matrices. This matrix-algebraic structure means that their fundamental properties—such as the probability density function (PDF), cumulative distribution function (CDF), and moments (like mean and variance)—can be calculated exactly and computed efficiently.⁹ This unique blend of flexibility and analytical tractability is the hallmark of the phase-type framework.

This report provides a comprehensive, self-contained guide to understanding and applying phase-type distributions. We will begin by building the necessary foundation in continuous-time Markov chains (CTMCs), the engine that drives the phase-based model. We will then formally define the PH distribution and its parameters, explore its mathematical properties, and examine a gallery of important special cases that connect the abstract theory to familiar distributions. Finally, we will demonstrate the practical power of this framework by modeling a real-world queuing problem. Throughout this journey, we will use the Python programming language, leveraging libraries such as NumPy, SciPy, and the specialized butools and phph packages, with interactive visualizations from Plotly to bring the underlying theories to life.

## **Section 1: The Foundation – Continuous-Time Markov Chains with an Absorbing State**

To truly understand phase-type distributions, one must first understand the machinery that generates them: the continuous-time Markov chain (CTMC). A CTMC is a stochastic model that describes a system transitioning between a finite set of discrete states over continuous time.¹³

### **1.1 An Intuitive Introduction to CTMCs**

Imagine a system that can be in one of several distinct conditions or states. For example, a piece of industrial equipment could be in one of three states: State 1: Operational, State 2: Minor Fault (under repair), or State 3: Decommissioned (End of Life). A CTMC models how the system jumps between these states over time.

The defining characteristic of this model is the **Markov property**: the probability of the system's future evolution depends *only* on its current state, not on the sequence of states that led it there.¹ If our machine is currently Operational, the chance it develops a Minor Fault in the next hour is the same regardless of whether it has been operational for 10 hours or 10,000 hours. This "memorylessness" applies to the transitions between states.

This leads to a crucial and foundational concept: the time the system spends in any given state before transitioning to a different one (known as the **sojourn time**) is always exponentially distributed.¹⁰ The parameter of this exponential distribution is simply the total rate of leaving that state. This is the fundamental link between the broader CTMC framework and the exponential building blocks of phase-type distributions.

Within this framework, states are classified into two types:

* **Transient States:** These are intermediate states that the process can enter and leave. In our example, Operational and Minor Fault are transient. The system can move from Operational to Minor Fault and potentially back again after repair.  
* **Absorbing States:** An absorbing state is a terminal state. Once the process enters an absorbing state, it can never leave.² In our example, Decommissioned is an absorbing state. The equipment's operational lifecycle has ended.

### **1.2 The Language of Transitions: The Infinitesimal Generator Matrix (Q)**

The entire dynamic behavior of a CTMC is encapsulated in a single, powerful mathematical object: the **infinitesimal generator matrix**, denoted by Q.⁹ This matrix contains all the instantaneous transition rates between the states of the system.

The structure of the Q matrix is defined as follows:

* The off-diagonal elements, q_{ij} (for i≠j), are non-negative real numbers representing the rate of transition from state i to state j. A higher value means a faster transition.  
* The diagonal elements, q_{ii}, are negative and are defined as the negative sum of all other elements in their row: q_{ii} = -∑_{j≠i} q_{ij}. Consequently, q_{ii} represents the total rate of *leaving* state i.  
* A key property that follows from this definition is that the sum of each row in the Q matrix corresponding to a transient state is zero.¹¹ For an absorbing state, its corresponding row in the Q matrix consists entirely of zeros, signifying that no transitions out of that state are possible.

Let's formalize this with our equipment analogy. Let the states be 1: Operational, 2: Minor Fault, and 3: Decommissioned (Absorbing). A possible Q matrix could be:

$$Q = \begin{pmatrix}
-0.15 & 0.1 & 0.05 \\
0.5 & -0.6 & 0.1 \\
0 & 0 & 0
\end{pmatrix}$$

This matrix tells us:

* From Operational (State 1), the rate of transition to Minor Fault (State 2) is 0.1, and the rate of transition to Decommissioned (State 3) is 0.05. The total rate of leaving State 1 is 0.1+0.05=0.15, so q_{11} = -0.15.  
* From Minor Fault (State 2), the rate of being repaired and returning to Operational (State 1) is 0.5, and the rate of being Decommissioned is 0.1. The total rate of leaving State 2 is 0.5+0.1=0.6, so q_{22} = -0.6.  
* From Decommissioned (State 3), all transition rates are 0, as it is an absorbing state.

### **1.3 Visualizing the Markov Chain Structure with Python and Plotly**

While the Q matrix is a complete mathematical description, it can be difficult to interpret intuitively. A state-transition diagram, which is a form of directed graph, provides a much clearer visual representation of the system's structure. The states of the CTMC become the nodes of the graph, and the non-zero transition rates become the directed, labeled edges between them.¹⁸

We can create a powerful, reusable Python function to generate such a diagram. A robust approach is to use the graphviz library, which contains sophisticated algorithms for determining the optimal layout of nodes and edges (e.g., using the dot engine), and then render this layout interactively using Plotly.²⁰ This combines the layout power of a dedicated graph library with the rich interactivity of a modern plotting framework.

```{python}
import numpy as np
import plotly.graph_objects as go
import networkx as nx
from plotly.offline import init_notebook_mode, iplot

def visualize_ctmc_simple(Q, state_names, title="Continuous-Time Markov Chain"):
    """
    Visualizes a Continuous-Time Markov Chain using NetworkX for layout and Plotly for rendering.
    
    Args:
        Q (np.ndarray): The infinitesimal generator matrix.
        state_names (list): A list of names for the states.
        title (str): The title of the plot.
    """
    num_states = Q.shape[0]
    
    # Create a directed graph
    G = nx.DiGraph()
    
    # Add nodes
    for i in range(num_states):
        G.add_node(i, label=state_names[i])
    
    # Add edges for non-zero transition rates
    for i in range(num_states):
        for j in range(num_states):
            rate = Q[i, j]
            if i != j and rate > 0:
                G.add_edge(i, j, rate=rate)
    
    # Use NetworkX to compute layout
    pos = nx.spring_layout(G, k=3, iterations=50)
    
    # Create Plotly figure
    fig = go.Figure()
    
    # Add edges
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        rate = G[edge[0]][edge[1]]['rate']
        
        # Add edge line
        fig.add_trace(go.Scatter(
            x=[x0, x1], y=[y0, y1],
            mode='lines',
            line=dict(width=2, color='grey'),
            showlegend=False,
            hoverinfo='none'
        ))
        
        # Add arrowhead annotation
        fig.add_annotation(
            x=x1, y=y1,
            ax=x0, ay=y0,
            xref='x', yref='y',
            axref='x', ayref='y',
            showarrow=True,
            arrowhead=2,
            arrowsize=1.5,
            arrowwidth=2,
            arrowcolor='grey'
        )
        
        # Add edge label
        mid_x, mid_y = (x0 + x1) / 2, (y0 + y1) / 2
        fig.add_annotation(
            x=mid_x, y=mid_y,
            text=f'{rate:.2f}',
            showarrow=False,
            font=dict(size=10, color="black"),
            bgcolor="white",
            bordercolor="black",
            borderwidth=1
        )
    
    # Add nodes
    node_x = [pos[node][0] for node in G.nodes()]
    node_y = [pos[node][1] for node in G.nodes()]
    node_text = [state_names[i] for i in G.nodes()]
    
    fig.add_trace(go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='middle center',
        marker=dict(
            symbol='circle',
            size=60,
            color='lightblue',
            line=dict(width=2, color='darkblue')
        ),
        hoverinfo='text',
        hovertext=node_text,
        showlegend=False
    ))
    
    fig.update_layout(
        title_text=title,
        showlegend=False,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='white',
        width=800,
        height=600
    )
    
    return fig

# --- Example Usage for our Equipment Analogy ---
Q_matrix = np.array([
    [-0.15, 0.1, 0.05],
    [0.5, -0.6, 0.1],
    [0, 0, 0]
])
state_names = ["Operational", "Minor Fault", "Decommissioned"]

# Generate and display the interactive plot
fig_ctmc = visualize_ctmc_simple(Q_matrix, state_names, title="CTMC for Equipment Lifecycle")
fig_ctmc.show()
```

The resulting interactive plot clearly shows the flow of the system: the equipment starts Operational, can transition to a Minor Fault state (and be repaired), and from either of these transient states, it can ultimately transition to the Decommissioned absorbing state. This visual tool provides an intuitive grasp of the system's dynamics, which is the essential first step toward understanding the distribution of the time it takes to reach that final state.

## **Section 2: Defining the Phase-Type Distribution**

With the foundation of continuous-time Markov chains established, we can now formally define the phase-type distribution. It is a direct and elegant consequence of the CTMC structure.

### **2.1 The Time Until Absorption**

A continuous phase-type (PH) distribution is formally defined as the distribution of the random variable X, which represents the **time until a CTMC reaches its single absorbing state**, given that it started in one of the transient states.³

The "phases" of the distribution are nothing more than the transient states of this underlying CTMC.⁵ The process evolves through these phases, spending an exponentially distributed amount of time in each one, until it is finally absorbed. The total time elapsed on this journey is the random variable that follows the phase-type distribution.

### **2.2 The Defining Parameters: (α,T)**

To work with a PH distribution, we do not need the full (m+1)×(m+1) generator matrix Q. Instead, we only need to characterize the behavior of the process *before* absorption. This is accomplished by partitioning the Q matrix, which isolates the components relevant to the transient states.⁵

Let a CTMC have m transient states (labeled 1 to m) and one absorbing state (labeled 0). The generator matrix Q can be written in block form as:

$$Q = \begin{pmatrix}
\mathbf{T} & \mathbf{t} \\
\mathbf{0} & 0
\end{pmatrix}$$

Here, the components are:

* **T**: This is an m×m matrix known as the **sub-intensity matrix** or **sub-generator**. It contains the transition rates *exclusively between the m transient states*. The diagonal elements are negative (representing the total rate of leaving each transient state for another transient state or the absorbing state), and the off-diagonal elements are non-negative.  
* **t**: This is an m×1 column vector called the **exit rate vector**. The i-th element of t contains the rate of transition from transient state i directly to the absorbing state.  
* **0**: This is a 1×m row vector of zeros, indicating that it is impossible to transition from the absorbing state back to any transient state.

A phase-type distribution is completely specified by two parameters derived from this structure:

1. **T**: The m×m sub-intensity matrix.  
2. **α** (alpha): A 1×m row vector known as the **initial probability vector**. The i-th element, α_i, is the probability that the process starts in transient state i. It is a requirement that ∑_{i=1}^m α_i = 1, which means the process is assumed to always begin in one of the transient states.⁵

A distribution defined this way is denoted as PH(α,T).

A crucial connection exists between T and t. Because the rows of the original generator matrix Q must sum to zero, the exit rate vector t is not an independent parameter. It is fully determined by the sub-intensity matrix T via the relationship:

$$\mathbf{t} = -\mathbf{T}\mathbf{1}$$

where **1** is an m×1 column vector of ones.⁵ This elegant equation links the internal dynamics among the transient phases (captured in T) to the dynamics of exiting the system entirely (captured in t).

### **2.3 Implementation with butools**

The butools library is a specialized, open-source Python package designed for the analysis of phase-type distributions and other matrix-analytic methods.²⁴ It provides a suite of optimized functions for creating, analyzing, and fitting these models.

To represent a PH distribution in butools, we simply define the initial probability vector α and the sub-intensity matrix T as numpy arrays. The library includes validation functions to ensure the defined parameters constitute a valid representation.

```{python}
import numpy as np
try:
    from butools.ph import CheckPHRepresentation
    butools_available = True
except ImportError:
    butools_available = False
    print("butools not available - using manual validation")

def manual_ph_check(alpha, T):
    """Manual validation of PH representation"""
    # Check alpha is a probability vector
    if not np.allclose(np.sum(alpha), 1.0):
        return False
    if np.any(alpha < 0):
        return False
    
    # Check T properties
    if T.shape[0] != T.shape[1]:
        return False
    if T.shape[1] != alpha.shape[1]:
        return False
    
    # Check diagonal elements are negative
    if np.any(np.diag(T) >= 0):
        return False
    
    # Check off-diagonal elements are non-negative
    T_offdiag = T - np.diag(np.diag(T))
    if np.any(T_offdiag < 0):
        return False
    
    return True

# --- Define the PH parameters for the Equipment Lifecycle model ---

# Initial probability vector alpha: Let's assume the process always starts in the 'Operational' state.
# alpha = [P(start in Op), P(start in Fault)]
alpha = np.array([[1.0, 0.0]])

# Sub-intensity matrix T: This is the upper-left 2x2 block of the full Q matrix.
# It describes transitions between 'Operational' and 'Minor Fault'.
#       Op      Fault
# Op  [-0.15,   0.1]
# Fault [ 0.5,    -0.6]
T = np.array([
    [-0.15, 0.1],
    [0.5, -0.6]
])

# Use butools to check if (alpha, T) is a valid PH representation.
if butools_available:
    is_valid_ph = CheckPHRepresentation(alpha, T)
else:
    is_valid_ph = manual_ph_check(alpha, T)

print(f"The defined (alpha, T) is a valid PH representation: {is_valid_ph}")

# The exit rate vector 't' can be calculated from T
# t = -T * 1
t = -T.dot(np.ones((T.shape[0], 1)))
print("\nSub-intensity matrix T:")
print(T)
print("\nInitial probability vector alpha:")
print(alpha)
print("\nCalculated exit rate vector t:")
print(t.flatten())
```

This simple code block illustrates the core data structures for a PH distribution. With α and T defined, we have everything needed to compute all properties of the distribution of the equipment's time until decommissioning.

## **Section 3: The Anatomy of a Phase-Type Distribution: Properties and Formulas**

The primary advantage of the phase-type framework is its analytical tractability. Once a system's time-to-event is modeled with a PH(α,T) representation, its key distributional properties can be computed directly using matrix algebra. This section unveils these fundamental formulas and demonstrates their implementation in Python.

### **3.1 The Power of Matrix Algebra**

The following closed-form expressions allow for the exact calculation of the probability density function (PDF), cumulative distribution function (CDF), and moments of a phase-type distribution.⁵

Let X∼PH(α,T) be a continuous phase-type random variable.

* **Probability Density Function (PDF)**: The probability density of the absorption time being exactly x is given by:  
  $$f(x) = \alpha e^{Tx} \mathbf{t}, \quad \text{for } x > 0$$
  where $\mathbf{t} = -\mathbf{T}\mathbf{1}$.  

* **Cumulative Distribution Function (CDF)**: The probability of the absorption time being less than or equal to x is given by:  
  $$F(x) = 1 - \alpha e^{Tx} \mathbf{1}, \quad \text{for } x \geq 0$$

* **Moments**: The k-th non-central moment of the absorption time, E[X^k], is given by:  
  $$E[X^k] = k! \alpha (-\mathbf{T})^{-k} \mathbf{1}$$
  This allows for direct calculation of the mean (k=1) and variance (E[X²]−(E[X])²).

The central mathematical operation in these formulas is the **matrix exponential**, e^{Tx}. This is not an element-wise operation but is defined by the same power series as the scalar exponential: e^A = ∑_{k=0}^∞ A^k/k!. It captures the evolution of the probabilities of being in the transient states over a time interval x.

### **3.2 Demystifying the Formulas with Python**

To make these abstract formulas concrete, we can implement them directly in Python. This exercise serves a pedagogical purpose, revealing exactly how the matrix operations translate into code, before we leverage the optimized functions available in specialized libraries.

```{python}
import numpy as np
import scipy.linalg
import plotly.graph_objects as go

# Try to import butools functions
try:
    from butools.ph import PdfFromPH, CdfFromPH, MomentsFromPH, CheckPHRepresentation
    butools_available = True
except ImportError:
    butools_available = False
    print("butools not available - using manual implementations")

# --- Define a 3-phase PH distribution for demonstration ---
alpha_demo = np.array([[0.8, 0.2, 0.0]])
T_demo = np.array([
    [-4.0, 2.0, 1.0],
    [0.0, -2.0, 1.5],
    [0.0, 0.0, -1.0]
])

# Manual validation
def validate_ph_manual(alpha, T):
    return (np.allclose(np.sum(alpha), 1.0) and 
            np.all(alpha >= 0) and 
            np.all(np.diag(T) < 0) and
            np.all(T - np.diag(np.diag(T)) >= 0))

print("Is the demo (alpha, T) a valid PH representation?", validate_ph_manual(alpha_demo, T_demo))

# --- 1. Implementation from Scratch ---
def pdf_from_scratch(x, alpha, T):
    """Calculates the PDF of a PH distribution manually."""
    if x <= 0:
        return 0.0
    t_vec = -T.dot(np.ones((T.shape[0], 1)))
    # scipy.linalg.expm computes the matrix exponential
    matrix_exp = scipy.linalg.expm(T * x)
    pdf_val = alpha.dot(matrix_exp).dot(t_vec)
    return pdf_val[0, 0]

def cdf_from_scratch(x, alpha, T):
    """Calculates the CDF of a PH distribution manually."""
    if x < 0:
        return 0.0
    ones_vec = np.ones((T.shape[0], 1))
    matrix_exp = scipy.linalg.expm(T * x)
    cdf_val = 1 - alpha.dot(matrix_exp).dot(ones_vec)
    return cdf_val[0, 0]

def moments_from_scratch(alpha, T, k):
    """Calculates the k-th moment of a PH distribution manually."""
    import math
    ones_vec = np.ones((T.shape[0], 1))
    T_inv_k = np.linalg.matrix_power(np.linalg.inv(-T), k)
    moment = math.factorial(k) * alpha.dot(T_inv_k).dot(ones_vec)
    return moment[0, 0]

# --- 2. Calculate properties for a specific time point, x=1.5 ---
x_val = 1.5

# Using "from scratch" functions
pdf_scratch = pdf_from_scratch(x_val, alpha_demo, T_demo)
cdf_scratch = cdf_from_scratch(x_val, alpha_demo, T_demo)

print(f"\n--- Comparison at x = {x_val} ---")
print(f"PDF (from scratch): {pdf_scratch:.6f}")
print(f"CDF (from scratch): {cdf_scratch:.6f}")

# Calculate moments using manual implementation
mean_scratch = moments_from_scratch(alpha_demo, T_demo, 1)
second_moment = moments_from_scratch(alpha_demo, T_demo, 2)
variance_scratch = second_moment - mean_scratch**2

print(f"\n--- Moments (manual calculation) ---")
print(f"Mean: {mean_scratch:.4f}")
print(f"Variance: {variance_scratch:.4f}")

# Compare with butools if available
if butools_available:
    pdf_butools = PdfFromPH(alpha_demo, T_demo, [x_val])[0]
    cdf_butools = CdfFromPH(alpha_demo, T_demo, [x_val])[0]
    moments_butools = MomentsFromPH(alpha_demo, T_demo, 2)
    
    print(f"PDF (butools):      {pdf_butools:.6f}")
    print(f"CDF (butools):      {cdf_butools:.6f}")
    print(f"Mean (butools):     {moments_butools[0]:.4f}")
    print(f"Variance (butools): {moments_butools[1] - moments_butools[0]**2:.4f}")
```

This example confirms the correctness of the formulas and showcases the convenience of using a specialized library like butools for practical work.

### **3.3 Interactive Visualization of PDF and CDF**

A static plot of a distribution is useful, but an interactive one is an exploratory tool. Using Plotly, we can create a dynamic chart that allows a user to inspect the PDF and CDF values at any point, zoom into regions of interest, and toggle the visibility of each curve.

```{python}
# --- Generate data for plotting ---
x_plot = np.linspace(0, 4, 400)

# Calculate PDF and CDF values
if butools_available:
    pdf_values = PdfFromPH(alpha_demo, T_demo, x_plot)
    cdf_values = CdfFromPH(alpha_demo, T_demo, x_plot)
else:
    pdf_values = [pdf_from_scratch(x, alpha_demo, T_demo) for x in x_plot]
    cdf_values = [cdf_from_scratch(x, alpha_demo, T_demo) for x in x_plot]

# --- Create the interactive Plotly figure ---
fig_pdf_cdf = go.Figure()

# Add PDF trace (Primary Y-axis)
fig_pdf_cdf.add_trace(go.Scatter(
    x=x_plot, y=pdf_values,
    mode='lines',
    name='PDF',
    line=dict(color='royalblue', width=2)
))

# Add CDF trace (Secondary Y-axis)
fig_pdf_cdf.add_trace(go.Scatter(
    x=x_plot, y=cdf_values,
    mode='lines',
    name='CDF',
    yaxis='y2',
    line=dict(color='firebrick', width=2, dash='dash')
))

# Update layout with titles and dual axes
fig_pdf_cdf.update_layout(
    title_text="Interactive PDF and CDF of a 3-Phase PH Distribution",
    xaxis_title="Time (x)",
    yaxis=dict(
        title="Probability Density (PDF)",
        titlefont=dict(color="royalblue"),
        tickfont=dict(color="royalblue")
    ),
    yaxis2=dict(
        title="Cumulative Probability (CDF)",
        titlefont=dict(color="firebrick"),
        tickfont=dict(color="firebrick"),
        anchor="x",
        overlaying="y",
        side="right",
        range=[0, 1.05] # Ensure CDF axis goes to 1
    ),
    legend=dict(x=0.7, y=0.2),
    plot_bgcolor='rgba(240, 240, 240, 0.95)',
    width=800,
    height=600
)

fig_pdf_cdf.show()
```

The resulting plot allows for a detailed examination of the distribution's shape. One can observe the mode of the PDF, the rate of increase of the CDF, and the probability mass contained within any interval by inspecting the values interactively.

## **Section 4: A Gallery of Common Phase-Type Structures**

One of the most powerful aspects of the phase-type framework is its ability to represent many well-known probability distributions as special cases. This section builds intuition by connecting the abstract (α,T) representation to these familiar models. For each, we provide the conceptual model, its CTMC diagram, its (α,T) structure, and its PDF.

### **4.1 The Building Block: Exponential Distribution**

The simplest non-trivial PH distribution is the exponential distribution itself.

* **Concept:** A process with a single transient phase that it leaves for the absorbing state at a constant rate λ.⁵  
* **Representation:** A 1-dimensional PH distribution with:  
  $$\boldsymbol{\alpha} = \begin{pmatrix} 1 \end{pmatrix}, \quad \mathbf{T} = \begin{pmatrix} -\lambda \end{pmatrix}$$  
* **CTMC Diagram:** A single node representing the phase, with a single arrow labeled λ pointing to an implicit absorbing state.

### **4.2 Sequential Tasks: The Erlang Distribution**

The Erlang distribution models the time to complete a sequence of identical tasks.

* **Concept:** A process that must pass through k sequential, identical exponential phases, each with rate λ. This is equivalent to the sum of k independent and identically distributed exponential random variables. It is often used to model processes with multiple, ordered stages, like an assembly line.⁵  
* **Representation:** A k-dimensional PH distribution where the process always starts in phase 1.  
  $$\boldsymbol{\alpha} = \begin{pmatrix} 1 & 0 & \cdots & 0 \end{pmatrix}$$
  $$\mathbf{T} = \begin{pmatrix}
  -\lambda & \lambda & 0 & \cdots & 0 \\
  0 & -\lambda & \lambda & \cdots & 0 \\
  \vdots & \vdots & \ddots & \ddots & \vdots \\
  0 & 0 & \cdots & -\lambda & \lambda \\
  0 & 0 & \cdots & 0 & -\lambda
  \end{pmatrix}$$
  The structure of T is bidiagonal, with -λ on the main diagonal and λ on the first superdiagonal.  
* **Key Property (Coefficient of Variation):** The Erlang distribution is less variable than the exponential. Its coefficient of variation (CV), the ratio of the standard deviation to the mean, is 1/√k. Since k≥1, the CV is always ≤1. As k→∞, the distribution approaches a deterministic value (a spike), representing a process with zero variance.

### **4.3 Parallel Tasks: The Hyperexponential Distribution**

The hyperexponential distribution models a choice between different types of tasks.

* **Concept:** A process that, at its start, probabilistically chooses one of n parallel, independent exponential phases. Phase i is chosen with probability p_i and has a service rate of λ_i. This is a mixture of exponential distributions. A classic analogy is a customer arriving at a bank and being randomly assigned to one of n tellers, each working at a different speed.⁵  
* **Representation:** An n-dimensional PH distribution where the starting probability vector defines the mixture.  
  $$\boldsymbol{\alpha} = \begin{pmatrix} p_1 & p_2 & \cdots & p_n \end{pmatrix}$$
  $$\mathbf{T} = \begin{pmatrix}
  -\lambda_1 & 0 & \cdots & 0 \\
  0 & -\lambda_2 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \cdots & -\lambda_n
  \end{pmatrix}$$
  The T matrix is diagonal, reflecting that the phases are parallel and independent; there are no transitions between them.  
* **Key Property (Coefficient of Variation):** The hyperexponential distribution is more variable than the exponential. Its CV is always ≥1. This makes it ideal for modeling processes with high variability or the presence of outliers, such as service times that are usually short but occasionally very long.

### **4.4 The Generalist: The Coxian Distribution**

The Coxian distribution provides a flexible structure that generalizes the Erlang model by allowing for early exits.

* **Concept:** A process moves through a sequence of k potentially non-identical phases. After completing phase i, it can either proceed to phase i+1 with probability p_i or exit to the absorbing state with probability 1-p_i. This structure can model multi-stage processes where failure or completion can occur at any stage.⁵  
* **Representation:** For a k-phase Coxian distribution starting in phase 1:  
  $$\boldsymbol{\alpha} = \begin{pmatrix} 1 & 0 & \cdots & 0 \end{pmatrix}$$
  $$\mathbf{T} = \begin{pmatrix}
  -\lambda_1 & p_1\lambda_1 & 0 & \cdots & 0 \\
  0 & -\lambda_2 & p_2\lambda_2 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \ddots & \vdots \\
  0 & 0 & \cdots & -\lambda_{k-1} & p_{k-1}\lambda_{k-1} \\
  0 & 0 & \cdots & 0 & -\lambda_k
  \end{pmatrix}$$
* **Key Property:** The Coxian distribution is of paramount importance because any **acyclic** phase-type distribution (one whose underlying CTMC contains no cycles) has an equivalent Coxian representation.⁵ This establishes it as a canonical form for a vast and highly applicable subclass of PH distributions.

### **4.5 Visualizing the Gallery and Summary Table**

To solidify these concepts, the following Python code generates the state-transition diagrams and PDF plots for each of these special cases.

```{python}
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- Define Representations for Special Cases ---
# 1. Exponential(lambda=1.5)
alpha_exp = np.array([[1.0]])
T_exp = np.array([[-1.5]])

# 2. Erlang(k=4, lambda=2)
k_erlang = 4
lambda_erlang = 2.0
alpha_erlang = np.zeros((1, k_erlang))
alpha_erlang[0, 0] = 1.0
T_erlang = np.diag([-lambda_erlang] * k_erlang)
for i in range(k_erlang - 1):
    T_erlang[i, i+1] = lambda_erlang

# 3. Hyperexponential(p=[0.7, 0.3], lambda=[1.0, 5.0])
alpha_hyper = np.array([[0.7, 0.3]])
T_hyper = np.array([
    [-1.0, 0.0],
    [0.0, -5.0]
])

# 4. Coxian(k=3, lambda=[2.0, 3.0, 1.0], p=[0.8, 0.5])
alpha_cox = np.array([[1.0, 0.0, 0.0]])
T_cox = np.array([
    [-2.0, 0.8 * 2.0, 0.0],
    [0.0, -3.0, 0.5 * 3.0],
    [0.0, 0.0, -1.0]
])

# --- Plotting ---
distributions = {
    "Exponential": (alpha_exp, T_exp),
    "Erlang": (alpha_erlang, T_erlang),
    "Hyperexponential": (alpha_hyper, T_hyper),
    "Coxian": (alpha_cox, T_cox)
}

fig = make_subplots(
    rows=2, cols=2, 
    subplot_titles=list(distributions.keys()),
    specs=[[{"secondary_y": False}, {"secondary_y": False}],
           [{"secondary_y": False}, {"secondary_y": False}]]
)

x_plot = np.linspace(0, 5, 500)
colors = ['blue', 'red', 'green', 'orange']

row_col_pairs = [(1, 1), (1, 2), (2, 1), (2, 2)]

for i, (name, (alpha, T)) in enumerate(distributions.items()):
    row, col = row_col_pairs[i]
    
    if butools_available:
        pdf_vals = PdfFromPH(alpha, T, x_plot)
    else:
        pdf_vals = [pdf_from_scratch(x, alpha, T) for x in x_plot]
    
    fig.add_trace(
        go.Scatter(x=x_plot, y=pdf_vals, mode='lines', name=name, 
                  line=dict(color=colors[i], width=2), showlegend=False),
        row=row, col=col
    )

fig.update_layout(
    title_text="PDFs of Special Case Phase-Type Distributions",
    height=700,
    showlegend=False
)

# Update x and y axis titles
for i in range(1, 3):
    for j in range(1, 3):
        fig.update_xaxes(title_text="Time", row=i, col=j)
        fig.update_yaxes(title_text="Density", row=i, col=j)

fig.show()

# Generate CTMC diagram for Erlang as an example
T_erlang_full = np.zeros((5, 5))
T_erlang_full[:4, :4] = T_erlang
t_erlang = -T_erlang.dot(np.ones((4, 1)))
T_erlang_full[:4, 4] = t_erlang.flatten()
erlang_names = [f"Phase {i+1}" for i in range(4)] + ["Absorbed"]

fig_erlang_ctmc = visualize_ctmc_simple(T_erlang_full, erlang_names, "CTMC for Erlang(4, 2) Distribution")
fig_erlang_ctmc.show()
```

To provide a clear, at-a-glance reference, the key features of these foundational structures are consolidated in the table below.

| Distribution Name | Conceptual Model | CTMC Diagram | (α,T) Structure | Coefficient of Variation (CV) | Typical Use Case |
|:------------------|:-----------------|:-------------|:----------------|:------------------------------|:-----------------|
| **Exponential** | Single memoryless phase | A single transient state leading to absorption. | α=[1], T=[-λ] | CV = 1 | Modeling events with a constant hazard rate (e.g., radioactive decay). |
| **Erlang** | Sum of k identical exponential variables | A linear sequence of k transient states. | α=[1,0,…], T is bidiagonal. | CV < 1 | Modeling multi-step processes with low variability (e.g., assembly lines). |
| **Hyperexponential** | Mixture of n parallel exponential variables | n parallel transient states, each leading to absorption. | α=[p₁,…,pₙ], T is diagonal. | CV > 1 | Modeling processes with high variability or mixed populations (e.g., call types). |
| **Coxian** | Sequence of phases with intermediate exits | A linear sequence of states with exits to absorption from each state. | α=[1,0,…], T is bidiagonal with probabilities. | CV can be < 1 or > 1 | Generalizing Erlang for processes with failure/completion at any stage. |

This gallery demonstrates how the abstract phase-type framework gives rise to a rich family of concrete, interpretable, and widely applicable distributions.

## **Section 5: A Practical Application – Modeling Service Times in a Call Center (PH/PH/c Queue)**

One of the most significant applications of phase-type distributions is in **queuing theory**, the mathematical study of waiting lines. While foundational models provide invaluable insights, their assumptions are often too rigid for real-world complexity. PH distributions offer a powerful way to bridge this gap, enabling the analysis of more realistic systems.³

### **5.1 Setting the Scene: The Challenge of Real-World Queues**

Queuing systems are typically described using **Kendall's notation**, A/S/c, where 'A' denotes the arrival process distribution, 'S' the service time distribution, and 'c' the number of parallel servers.³⁶ The classic M/M/c model, which assumes Poisson arrivals (M for Markovian/memoryless) and exponentially distributed service times (M), is analytically simple but often unrealistic.³⁷

Consider a technical support call center. Service times are rarely purely exponential. A single queue might handle a mix of very quick interactions (e.g., password resets), moderately long calls (e.g., configuration help), and a few extremely lengthy, complex troubleshooting sessions. An exponential service model, with its constant hazard rate, cannot capture this kind of variability. This is where PH distributions provide a solution. By replacing the exponential service time distribution with a more flexible PH distribution, we can construct a more realistic M/PH/c (Poisson arrivals, PH service) or even a PH/PH/c (PH arrivals, PH service) queue, which can be analyzed using matrix-analytic methods.¹²

### **5.2 Building a Call Center Model**

Let's model a call center with the following characteristics:

* **Servers:** c=5 agents.  
* **Arrival Process:** Calls arrive in a pattern that is slightly more regular than pure random (Poisson). We can model this using an **Erlang-2 distribution**, which has a coefficient of variation less than 1. Let's use Erlang(2,12).  
* **Service Process:** Service times are highly variable, consisting of a mix of three types of calls. We can model this with a **3-phase Hyperexponential distribution**.  
  * 70% of calls are quick (average 30 seconds, or a rate of 2 calls/minute).  
  * 25% of calls are standard (average 2 minutes, or a rate of 0.5 calls/minute).  
  * 5% of calls are complex (average 10 minutes, or a rate of 0.1 calls/minute).

```{python}
import numpy as np

# Try to import specialized libraries
try:
    import phph
    phph_available = True
except ImportError:
    phph_available = False
    print("phph library not available - using manual calculations")

# --- 1. Define the Arrival Process: Erlang(k=2, rate=12) ---
k_arr, lambda_arr = 2, 12.0
alpha_arr = np.array([[1.0, 0.0]])
T_arr = np.array([
    [-lambda_arr, lambda_arr],
    [0.0, -lambda_arr]
])

# --- 2. Define the Service Process: Hyperexponential-3 ---
# Probabilities (p_i) and rates (lambda_i)
probs_srv = [0.70, 0.25, 0.05]
rates_srv = [2.0, 0.5, 0.1]  # calls per minute

alpha_srv = np.array([probs_srv])
T_srv = np.diag([-r for r in rates_srv])

# --- 3. Calculate Mean Rates for Context ---
if butools_available:
    mean_arrival_time = MomentsFromPH(alpha_arr, T_arr, 1)[0]
    mean_service_time = MomentsFromPH(alpha_srv, T_srv, 1)[0]
else:
    mean_arrival_time = moments_from_scratch(alpha_arr, T_arr, 1)
    mean_service_time = moments_from_scratch(alpha_srv, T_srv, 1)

mean_arrival_rate = 1 / mean_arrival_time
mean_service_rate = 1 / mean_service_time

print("--- Model Parameters ---")
print(f"Mean inter-arrival time: {mean_arrival_time:.4f} minutes")
print(f"Mean arrival rate (lambda): {mean_arrival_rate:.4f} calls/minute")
print(f"Mean service time: {mean_service_time:.4f} minutes")
print(f"Mean service rate per agent (mu): {mean_service_rate:.4f} calls/minute")

# --- 4. Analyze the Queue using approximations ---
servers = 5
rho = mean_arrival_rate / (servers * mean_service_rate)  # Traffic intensity

print(f"\n--- Queue Performance Analysis ---")
print(f"Number of agents (c): {servers}")
print(f"Traffic intensity (rho): {rho:.4f}")

if rho < 1:
    print("System is stable (rho < 1)")
    
    # Simple approximations for M/G/c queue
    # These are rough approximations - actual PH/PH/c analysis would be more complex
    ca_squared = 1  # Coefficient of variation squared for arrivals (Erlang-2)
    cs_squared = sum(probs_srv[i] * (1/rates_srv[i])**2 for i in range(3)) / mean_service_time**2
    
    print(f"Service CV²: {cs_squared:.4f}")
    
    # Approximate utilization and waiting time
    utilization = rho
    approx_wait_time = (cs_squared + ca_squared) / 2 * mean_service_time * rho / (1 - rho)
    
    print(f"Expected utilization: {utilization:.4f}")
    print(f"Approximate expected waiting time: {approx_wait_time:.4f} minutes")
    print(f"Approximate probability of waiting: {rho:.4f}")
    
else:
    print("System is unstable (rho >= 1)")

# --- 5. Visualize the Service Time Distribution ---
x_plot = np.linspace(0, 15, 500)

if butools_available:
    pdf_service = PdfFromPH(alpha_srv, T_srv, x_plot)
else:
    pdf_service = [pdf_from_scratch(x, alpha_srv, T_srv) for x in x_plot]

fig_service_pdf = go.Figure()
fig_service_pdf.add_trace(go.Scatter(
    x=x_plot, y=pdf_service,
    mode='lines', name='Service Time PDF',
    fill='tozeroy',
    line=dict(color='darkgreen', width=2)
))
fig_service_pdf.update_layout(
    title="PDF of Hyperexponential Service Time Distribution",
    xaxis_title="Service Time (minutes)",
    yaxis_title="Probability Density",
    plot_bgcolor='white',
    width=800,
    height=600
)
fig_service_pdf.show()
```

### **5.3 Interpreting and Visualizing the Results**

The output of the Python script provides critical insights for the call center manager. The KPIs reveal important characteristics of the system's performance under the given parameter settings.

The visualization of the service time PDF is equally revealing. The plot shows a sharp peak near zero, corresponding to the high volume of quick calls. However, it also displays a long, "heavy" tail that decays slowly. This tail represents the small fraction of very complex, time-consuming calls. It is this tail that an M/M/c model would fail to capture, likely leading to a significant underestimation of system congestion and customer wait times. The ability of the hyperexponential PH distribution to accurately model this high variability is what makes the analysis robust and realistic.

This application demonstrates the end-to-end power of the phase-type framework: constructing realistic models of system components based on their underlying processes, combining them into a system-level model, and deriving precise, actionable performance metrics through matrix-analytic computation.

## **Conclusion: The Power of a Phase-Based Approach**

This report has journeyed from the foundational principles of continuous-time processes to the practical application of a sophisticated modeling tool. We began with the simple, memoryless exponential distribution, saw how it serves as the temporal glue within a Continuous-Time Markov Chain, and from this structure, we defined the phase-type distribution. This journey reveals a framework of remarkable depth and utility.

The core value of phase-type distributions lies in their unique synthesis of two critical properties: **modeling flexibility** and **analytical tractability**.⁷ The denseness property ensures that PH distributions can approximate virtually any positive-valued random phenomenon, freeing modellers from the constraints of simpler, less realistic distributions. Simultaneously, their matrix-algebraic representation ensures that this flexibility does not come at the cost of computational feasibility. Key characteristics like the PDF, CDF, and moments are not just approximated but are calculated exactly through elegant matrix formulas, a feature we demonstrated with Python implementations.

By exploring the gallery of special cases—from the sequential Erlang to the parallel Hyperexponential—we have built an intuition for how different process structures map to different distributional shapes. This understanding is crucial for selecting an appropriate model for a given real-world scenario, as demonstrated in our queuing theory application. The ability to model a complex call center's service time with a Hyperexponential distribution showcases the practical power of this approach for performance engineering and capacity planning.

The path to mastering stochastic modeling is ongoing, and phase-type distributions are a gateway to even more advanced topics. For the interested reader, several avenues for further learning present themselves:

* **Fitting to Data:** This report assumed the (α,T) parameters were known. In practice, they are often estimated from empirical data. Powerful techniques like the Expectation-Maximization (EM) algorithm or moment-matching methods are used for this purpose, and are implemented in libraries like butools and the standalone EMpht program.⁵  
* **Modeling Heavy Tails:** Standard PH distributions are "light-tailed," meaning their tails decay exponentially. While sufficient for many applications, they cannot natively model phenomena with extreme outliers (e.g., financial crashes, internet file sizes). Extensions such as Matrix-Pareto distributions have been developed to address this limitation.⁷  
* **Multivariate Modeling:** Many systems involve multiple, dependent random variables (e.g., the height and weight of a person, or the correlated costs of different claims from a single insurance event). Multivariate phase-type (MPH) distributions extend the framework to model such dependent lifetimes, opening up applications in fields from finance to population genetics.⁴³

In conclusion, the phase-type distribution is more than just another statistical tool; it is a complete modeling paradigm. It provides a structured, powerful, and computationally efficient language for describing and analyzing the vast array of real-world processes that unfold over time.

---

**References:**

1. Chapter 8: Markov Chains, accessed on July 15, 2025, https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf
2. A simple introduction to Markov Chains | by Akif Mustafa - Medium, accessed on July 15, 2025, https://medium.com/@akif.iips/a-simple-introduction-to-markov-chains-723ea7097ce2
3. Phase-Type distribution (PH Distribution) - Statistics How To, accessed on July 15, 2025, https://www.statisticshowto.com/phase-type-distribution/
4. Phase-Type Distributions: explorations for applications in Epidemiology - Utrecht University Student Theses Repository Home, accessed on July 15, 2025, https://studenttheses.uu.nl/bitstream/handle/20.500.12932/39146/Bachelorthesis_Roman_Olff_5974275.pdf?sequence=1
5. Phase-type distribution - Wikipedia, accessed on July 15, 2025, https://en.wikipedia.org/wiki/Phase-type_distribution
6. Phase-Type Distribution | PDF | Mathematical Analysis | Statistical Theory - Scribd, accessed on July 15, 2025, https://www.scribd.com/document/662412891/Phase-type-distribution
7. Full article: Continuous scaled phase-type distributions, accessed on July 15, 2025, https://www.tandfonline.com/doi/full/10.1080/15326349.2022.2089683
8. Modeling and analysis of system reliability using phase‐type distribution closure properties, accessed on July 15, 2025, https://www.researchgate.net/publication/338838484_Modeling_and_analysis_of_system_reliability_using_phase-type_distribution_closure_properties
9. Phase-type distributions, defined as the distributions of absorption times of certain Markov jump processes, constitute a class - Cambridge University Press, accessed on July 15, 2025, https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3AA72038185F8A978F6FC201A438D9D3/S0515036100014100a.pdf/review_on_phasetype_distributions_and_their_use_in_risk_theory.pdf
10. A Review on Phase-Type Distributions and Their Use in Risk Theory - ResearchGate, accessed on July 15, 2025, https://www.researchgate.net/publication/241309412_A_Review_on_Phase-Type_Distributions_and_Their_Use_in_Risk_Theory
11. PhaseTypeR: phase-type distributions in R with reward ... - bioRxiv, accessed on July 15, 2025, https://www.biorxiv.org/content/10.1101/2022.06.16.496381v1.full.pdf
12. Mastering Phase-Type Distribution - Number Analytics, accessed on July 15, 2025, https://www.numberanalytics.com/blog/mastering-phase-type-distribution
13. Tutorial on Structured Continuous-Time Markov Processes - Journal of Artificial Intelligence Research, accessed on July 15, 2025, https://jair.org/index.php/jair/article/download/10921/26035/20379
14. 15. Continuous-Time Chains - Random Services, accessed on July 15, 2025, https://www.randomservices.org/random/markov/Continuous.html
15. Notes for Math 450 Continuous-time Markov chains and Stochastic Simulation, accessed on July 15, 2025, https://www.math.wustl.edu/~feres/Math450Lect05.pdf
16. continuous scaled phase-type distributions - Serval, accessed on July 15, 2025, https://serval.unil.ch/resource/serval:BIB_6D31E93470C9.P002/REF.pdf
17. Introduction to Continuous-Time Markov Chains (CTMCs) With Solved Examples || Tutorial 9 (A) - YouTube, accessed on July 15, 2025, https://www.youtube.com/watch?v=mPtyMuHMEzs
18. Markov Chains explained visually - Setosa.IO, accessed on July 15, 2025, https://setosa.io/ev/markov-chains/
19. Visualizing a Markov Chain - Will Hipson, accessed on July 15, 2025, https://willhipson.netlify.app/post/markov-sim/markov_chain/
20. Graphviz, order of nodes in left-to-right digraph (Markov chain) - Stack Overflow, accessed on July 15, 2025, https://stackoverflow.com/questions/38293129/graphviz-order-of-nodes-in-left-to-right-digraph-markov-chain
21. User Guide — graphviz 0.21 documentation, accessed on July 15, 2025, https://graphviz.readthedocs.io/en/stable/manual.html
22. vladignatyev/markovfsm: Markov chain and Probabilistic Automaton implementation in Python with nifty visualisation using Graphviz - GitHub, accessed on July 15, 2025, https://github.com/vladignatyev/markovfsm
23. Phase-Type Distribution and Moment Matching | MoDCS, accessed on July 15, 2025, https://www.modcs.org/wp-content/uploads/2015/12/Phase-Type%20Distribution%20and%20Moment%20Matching.pdf
24. Tools for Phase-Type Distributions (butools.ph), accessed on July 15, 2025, http://webspn.hit.bme.hu/~telek/tools/butools/doc/ph.html
25. BuTools V2.0, accessed on July 15, 2025, http://webspn.hit.bme.hu/~telek/tools/butools/index.php?page=34
26. BuTools V2.0, accessed on July 15, 2025, http://webspn.hit.bme.hu/~telek/tools/butools/index.php?page=2
27. Phase-type Distributions - BME, accessed on July 15, 2025, http://webspn.hit.bme.hu/~bodrog/publicat/res12.pdf
28. Generating Random Variates from a Distribution of Phase Type - Winter Simulation Conference, accessed on July 15, 2025, https://informs-sim.org/wsc81papers/1981_0051.pdf
29. The hyperexponential and hypoexponential distributions - Topics in Actuarial Modeling, accessed on July 15, 2025, https://actuarialmodelingtopics.wordpress.com/2016/08/01/the-hyperexponential-and-hypoexponential-distributions/
30. 1 Basic concepts from probability theory, accessed on July 15, 2025, https://iadan.win.tue.nl/sdp/h1.pdf
31. Hyperexponential Distribution: Theory and Practice - Number Analytics, accessed on July 15, 2025, https://www.numberanalytics.com/blog/hyperexponential-distribution-theory-practice
32. Hyperexponential Distribution - Statistics How To, accessed on July 15, 2025, https://www.statisticshowto.com/hyperexponential-distribution/
33. On the use of Phase-Type distributions for modeling general distributed events in manufacturing systems - POLITesi - Politecnico di Milano, accessed on July 15, 2025, https://www.politesi.polimi.it/retrieve/a81cb059-85af-616b-e053-1605fe0a889a/POLITECNICO%20DI%20MILANO.pdf
34. www.numberanalytics.com, accessed on July 15, 2025, https://www.numberanalytics.com/blog/mastering-phase-type-distribution#:~:text=Phase%2DType%20Distribution%20plays%20a,way%20to%20capture%20these%20complexities.
35. The Application of Phase Type Distributions for Modelling Queuing Systems ( )= - International Institute of Informatics and Cybernetics, accessed on July 15, 2025, https://iiisci.org/Journal/pdv/sci/pdfs/S253GDB.pdf
36. Queueing theory - Wikipedia, accessed on July 15, 2025, https://en.wikipedia.org/wiki/Queueing_theory
37. Queueing Theory in Call Centers - Specialty Answering Service, accessed on July 15, 2025, https://www.specialtyansweringservice.net/wp-content/uploads/resources_papers/queueing-theory-call-centers/Queueing-Theory-and-Call-Centers.pdf
38. (PDF) Queueing Models of Call Centers: An Introduction - ResearchGate, accessed on July 15, 2025, https://www.researchgate.net/publication/225231524_Queueing_Models_of_Call_Centers_An_Introduction
39. Queueing theory using Python | by Hamza Belabbes - Medium, accessed on July 15, 2025, https://medium.com/@hamza.ensmm/basic-queueing-theory-using-python-db351c1a5164
40. areenberg/phph: A Python package for PH/PH/c queueing ... - GitHub, accessed on July 15, 2025, https://github.com/areenberg/phph
41. Phase-type distributions & mixtures of Erlangs - KU Leuven, accessed on July 15, 2025, https://feb.kuleuven.be/public/u0092536/Verbelen,%20R.%20(2013).%20Phase-type%20distributions%20&%20mixtures%20of%20Erlangs.%20A%20study%20of%20theoretical%20concepts,%20calibration%20techniques%20&%20actuarial%20applications.pdf
42. Pat-Laub/EMpht.jl: [Julia Package] Fitting Phase-Type Distributions using an EM Algorithm, accessed on July 15, 2025, https://github.com/Pat-Laub/EMpht.jl
43. arXiv:2110.05179v5 [math.PR] 22 Dec 2022, accessed on July 15, 2025, https://arxiv.org/pdf/2110.05179
44. Graph-based algorithms for phase-type distributions - bioRxiv, accessed on July 15, 2025, https://www.biorxiv.org/content/10.1101/2022.03.12.484077.full
45. PhaseTypeR: phase-type distributions in R with reward transformations and a view towards population genetics | bioRxiv, accessed on July 15, 2025, https://www.biorxiv.org/content/10.1101/2022.06.16.496381.full